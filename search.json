[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "JinghongOu Diary",
    "section": "",
    "text": "Preface\nThis is Jinghong Ou’s learning diary of remotely sensing."
  },
  {
    "objectID": "Diary1.html#summary",
    "href": "Diary1.html#summary",
    "title": "1  Diary: Introduction",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nThe content of this week mainly outlines the content of the remoting sensing course from the aspects of passive and active sensor, data format type of remoting sensing, and data resolution type. Sensors are mainly divided into two types: passive and active. Both of them process the collected electromagnetic waves, with the difference that passive waves are collected from sources such as the sun, while active waves are collected from waves reflected after the sensor actively emits them. The data format is mainly divided into two aspects: raster and LiDAR, and raster is the main data type in this field. Resolution is divided into four aspects: spectral, spatial, temporal, and radiometric.\n\n\n\nSummary of introduction lecture (made by author, 2023)\n\n\nRegarding sensors, they are mainly mounted on platforms such as satellites, planes, drones, phones, and other handheld devices (Andy, n.d.). Common sensors include ultraviolet remote sensing sensors, visible light remote sensing sensors, infrared remote sensing sensors, and microwave remote sensing sensors (Sensorexpert, n.d.). Among these types of remote sensing sensors, common devices include cameras, scanners, multispectral cameras, etc., and common devices in microwave remote sensing sensors include radiometers, altimeters, real aperture radars, and synthetic aperture radars. In the following, I will mainly introduce my learning about the application of synthetic aperture radar."
  },
  {
    "objectID": "Diary1.html#sar-application",
    "href": "Diary1.html#sar-application",
    "title": "1  Diary: Introduction",
    "section": "1.2 SAR application",
    "text": "1.2 SAR application\nSAR data consist of high-resolution reflected returns of radar-frequency energy from terrain that has been illuminated by a directed beam of pulses generated by the sensor. The radar returns from the terrain are mainly determined by the physical characteristics of the surface features (such as surface roughness, geometric structure, and orientation), the electrical characteristics (dielectric constant, moisture content, and conductivity), and the radar frequency of the sensor. By supplying its own source of illumination, the SAR sensor can acquire data day or night without regard to cloud cover (Ciesin, n.d.).\nOne of the limitations of working with SAR data has been the somewhat tedious preprocessing steps that lower-level SAR data requires. Depending on the type of analysis you want to do, these preprocessing steps can include: applying the orbit file, radiometric calibration, de-bursting, multilooking, speckle filtering, and terrain correction (Earth Science Data Systems 2020)."
  },
  {
    "objectID": "Diary1.html#reflection",
    "href": "Diary1.html#reflection",
    "title": "1  Diary: Introduction",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nThese sensors give us the opportunity to observe the Earth from a broader perspective (from the air) and digitize and quantify the observations for further classification and analysis. Processing this data is key to the field, as more accurate data will result in more accurate outcomes, guiding policy, research, and commerce.\nI’m particularly fascinated by the surveillance capabilities of these sensors. By capturing aerial images, we can gain valuable insights into surface conditions such as urban areas, farmland, and rivers, allowing us to stay up-to-date with any changes on the ground. Essentially, the emergence of sensors has revolutionized space management, providing us with digital tools for real-time monitoring and making space management significantly more manageable.\n\n\n\n\nAndy, MacLachlan. n.d. “Remotely Sensing Cities and Environments.” https://andrewmaclachlan.github.io/CASA0023-lecture-1/#1.\n\n\nCiesin. n.d. “Synthetic Aperture Radar (SAR) Sensors.” http://www.ciesin.org/TG/RS/sarsens.html.\n\n\nEarth Science Data Systems, NASA. 2020. “What Is Synthetic Aperture Radar?” https://www.earthdata.nasa.gov/learn/backgrounders/what-is-sar.\n\n\nSensorexpert. n.d. “遥感传感器类型有哪些？看完这篇你就明白了.” https://www.sensorexpert.com.cn/article/21362.html."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Andy, MacLachlan. n.d. “Remotely Sensing Cities and\nEnvironments.” https://andrewmaclachlan.github.io/CASA0023-lecture-1/#1.\n\n\nChavez, Pat S. 1988. “An Improved Dark-Object Subtraction\nTechnique for Atmospheric Scattering Correction of Multispectral\nData.” Remote Sensing of Environment 24 (3): 459–79. https://doi.org/10.1016/0034-4257(88)90019-3.\n\n\nCiesin. n.d. “Synthetic Aperture Radar (SAR) Sensors.” http://www.ciesin.org/TG/RS/sarsens.html.\n\n\nEarth Science Data Systems, NASA. 2020. “What Is Synthetic\nAperture Radar?” https://www.earthdata.nasa.gov/learn/backgrounders/what-is-sar.\n\n\nGitelson, Anatoly A., Andrés Viña, Timothy J. Arkebauer, Donald C.\nRundquist, Galina Keydan, and Bryan Leavitt. 2003. “Remote\nEstimation of Leaf Area Index and Green Leaf Biomass in Maize\nCanopies.” Geophysical Research Letters 30 (5). https://doi.org/10.1029/2002GL016450.\n\n\nKim, Do-Hyung, Joseph O. Sexton, Praveen Noojipady, Chengquan Huang,\nAnupam Anand, Saurabh Channan, Min Feng, and John R. Townshend. 2014.\n“Global, Landsat-Based Forest-Cover Change from 1990 to\n2000.” Remote Sensing of Environment 155 (December):\n178–93. https://doi.org/10.1016/j.rse.2014.08.017.\n\n\nKloog, Itai, Alexandra A. Chudnovsky, Allan C. Just, Francesco Nordio,\nPetros Koutrakis, Brent A. Coull, Alexei Lyapustin, Yujie Wang, and Joel\nSchwartz. 2014. “A New Hybrid Spatio-Temporal Model for Estimating\nDaily Multi-Year PM2.5 Concentrations Across Northeastern USA Using High\nResolution Aerosol Optical Depth Data.” Atmospheric\nEnvironment 95 (October): 581–90. https://doi.org/10.1016/j.atmosenv.2014.07.014.\n\n\nPal, M. 2005. “Random Forest Classifier for Remote Sensing\nClassification.” International Journal of Remote Sensing\n26 (1): 217–22. https://doi.org/10.1080/01431160412331269698.\n\n\nPekel, Jean-François, Andrew Cottam, Noel Gorelick, and Alan S. Belward.\n2016. “High-Resolution Mapping of Global Surface Water and Its\nLong-Term Changes.” Nature 540 (7633): 418–22. https://doi.org/10.1038/nature20584.\n\n\nSensorexpert. n.d.\n“遥感传感器类型有哪些？看完这篇你就明白了.” https://www.sensorexpert.com.cn/article/21362.html.\n\n\nToutin, T. 2004. “Review article: Geometric processing of remote\nsensing images: models, algorithms and methods.”\nInternational journal of remote sensing 25 (10): 18931924. https://doi.org/10.1080/0143116031000101611.\n\n\nWu, Yanyan, Shuyuan Li, and Shixiao Yu. 2015. “Monitoring Urban\nExpansion and Its Effects on Land Use and Land Cover Changes in\nGuangzhou City, China.” Environmental Monitoring and\nAssessment 188 (1): 54. https://doi.org/10.1007/s10661-015-5069-2."
  },
  {
    "objectID": "Diary3.html",
    "href": "Diary3.html",
    "title": "Diary 3:",
    "section": "",
    "text": "##Summary\nThis week we focus on Remote Sensing Data Corrections, Joining, and Enhancement. It involve several key processes to ensure the accuracy and usability of satellite and aerial imagery. These corrections and enhancements can be broadly classified into the following categories: 1. Geometric Corrections: These involve correcting image distortions caused by sensor geometry, earth curvature, and platform motion. The general steps include identifying control points, selecting a suitable resampling technique, and applying a geometric transformation to correct the image. 2. Atmospheric Corrections: These help remove the influence of the atmosphere on the remotely sensed data. Methods include: a. Dark Object Subtraction (DOS): Assumes that the darkest pixel values in an image correspond to zero reflectance, allowing for atmospheric haze removal. b. Pseudo-Invariant Features (PIFs): Utilizes stable targets on Earth’s surface with consistent reflectance to correct for atmospheric effects. c. Atmospheric Radiative Transfer Models: Simulate the interaction of solar radiation with the Earth’s atmosphere to correct for atmospheric scattering and absorption. d. Empirical Line Correction: Relates the radiance values of ground-based measurements to the corresponding pixel values in the image to correct for atmospheric effects. 3. Orthorectification Correction: Involves correcting for terrain-induced geometric distortions in the image by using elevation data and projecting the image onto a map coordinate system, resulting in an orthorectified image. 4. Radiometric Calibration: Ensures the consistency and comparability of images by converting raw digital numbers to physical units, such as radiance or reflectance. This enables accurate comparisons between images acquired at different times and under varying conditions. 5. Data Joining and Enhancement: Enhances the visual quality and usability of images by merging and improving their features. Techniques include: a. Feathering: Smoothly blends adjacent images to create seamless mosaics without visible seams or discontinuities. b. Image Enhancement: Improves the visual appearance and interpretability of images using techniques such as contrast stretching, histogram equalization, and filtering."
  },
  {
    "objectID": "Diary3.html#summary",
    "href": "Diary3.html#summary",
    "title": "3  Diary: Remote sensing data",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nThis week we focus on Remote Sensing Data Corrections, Joining, and Enhancement. It involve several key processes to ensure the accuracy and usability of satellite and aerial imagery. These corrections and enhancements can be broadly classified into the following categories:\n\n\nGeometric Corrections: These involve correcting image distortions caused by sensor geometry, earth curvature, and platform motion. The general steps include identifying control points, selecting a suitable resampling technique, and applying a geometric transformation to correct the image.\nAtmospheric Corrections: These help remove the influence of the atmosphere on the remotely sensed data. Methods include: a. Dark Object Subtraction (DOS): Assumes that the darkest pixel values in an image correspond to zero reflectance, allowing for atmospheric haze removal. b. Pseudo-Invariant Features (PIFs): Utilizes stable targets on Earth’s surface with consistent reflectance to correct for atmospheric effects. c. Atmospheric Radiative Transfer Models: Simulate the interaction of solar radiation with the Earth’s atmosphere to correct for atmospheric scattering and absorption. d. Empirical Line Correction: Relates the radiance values of ground-based measurements to the corresponding pixel values in the image to correct for atmospheric effects.\nOrthorectification Correction: Involves correcting for terrain-induced geometric distortions in the image by using elevation data and projecting the image onto a map coordinate system, resulting in an orthorectified image.\nRadiometric Calibration: Ensures the consistency and comparability of images by converting raw digital numbers to physical units, such as radiance or reflectance. This enables accurate comparisons between images acquired at different times and under varying conditions.\nData Joining and Enhancement: Enhances the visual quality and usability of images by merging and improving their features. Techniques include: a. Feathering: Smoothly blends adjacent images to create seamless mosaics without visible seams or discontinuities. b. Image Enhancement: Improves the visual appearance and interpretability of images using techniques such as contrast stretching, histogram equalization, and filtering."
  },
  {
    "objectID": "Diary3.html#application",
    "href": "Diary3.html#application",
    "title": "3  Diary: Remote sensing data",
    "section": "3.2 Application",
    "text": "3.2 Application\nDark Object Subtraction (DOS) Application Example: DOS has been widely used in the processing of remote sensing data, particularly in the field of land cover and land use classification. One such example is the monitoring of water quality in coastal and inland water bodies. In this context, DOS is applied to correct for atmospheric effects, particularly scattering caused by aerosols and water vapor (Chavez 1988).\nGeometric Corrections Application Example: Geometric corrections are essential for various remote sensing applications, such as change detection and land cover mapping. One example is the creation of accurate and up-to-date maps for urban planning and management. In this case, geometric corrections are applied to high-resolution satellite images to ensure proper alignment with existing maps or other geospatial data. This ensures that the analysis and decision-making processes are based on accurate and consistent information (Toutin 2004)."
  },
  {
    "objectID": "Diary3.html#reflection",
    "href": "Diary3.html#reflection",
    "title": "3  Diary: Remote sensing data",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nRemote sensing data corrections and joining are fascinating as they play a crucial role in ensuring the quality and reliability of remotely sensed data. What’s interesting is how these processes address the inherent challenges and limitations of satellite and aerial imagery, such as distortions, atmospheric interference, and inconsistencies between different datasets. The data and tools used for corrections and joining will continue to be useful in the future for several reasons:\n\nGrowing demand for accurate geospatial data: As remote sensing technology advances and more satellites are launched, there will be an increasing need for accurate and consistent geospatial data to support various applications, including urban planning, disaster management, and environmental monitoring.\nIntegration of diverse data sources: Remote sensing data corrections and joining techniques will be crucial in integrating data from various sensors and platforms, ensuring seamless data fusion and enhancing the overall value of the information derived from these sources.\nImproved algorithms and computational capabilities: Advancements in algorithms, artificial intelligence, and computing power will enable more sophisticated and efficient data correction and joining techniques, leading to higher-quality remote sensing data products.\nEvolution of sensors and platforms: As sensors and platforms evolve, there may be new types of distortions, artifacts, or inconsistencies that need to be addressed. Remote sensing data corrections and joining techniques will have to adapt and expand to cater to these changes.\n\nWhile remote sensing data corrections and joining techniques are expected to remain useful, there may be limitations in their current form. For instance, some methods might not be applicable to new sensors or data types, requiring further research and development. Additionally, as the volume of remote sensing data grows exponentially, more efficient and automated techniques will be required to process and manage these datasets. In this context, the development of new tools and approaches, potentially leveraging artificial intelligence and machine learning, could be essential to keep up with future demands.\n\n\n\n\nChavez, Pat S. 1988. “An Improved Dark-Object Subtraction Technique for Atmospheric Scattering Correction of Multispectral Data.” Remote Sensing of Environment 24 (3): 459–79. https://doi.org/10.1016/0034-4257(88)90019-3.\n\n\nToutin, T. 2004. “Review article: Geometric processing of remote sensing images: models, algorithms and methods.” International journal of remote sensing 25 (10): 18931924. https://doi.org/10.1080/0143116031000101611."
  },
  {
    "objectID": "Diary2.html",
    "href": "Diary2.html",
    "title": "2  Diary: presentation",
    "section": "",
    "text": "3 Work package"
  },
  {
    "objectID": "Diary4.html#summary",
    "href": "Diary4.html#summary",
    "title": "4  Diary: Policy application",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nRemote sensing offers various applications for addressing urban issues, including:\n1. Urban Expansion: Landsat data can help monitor urban growth and land use changes, enabling better management of urban development.\n2. Air Pollution and Land Use/Land Cover (LULC): Sentinel-3 and Sentinel-5 data can be utilized to assess air quality and LULC changes, supporting policy decisions on pollution control and environmental protection.\n3. Urban Green Spaces: Landsat and Sentinel data can be used to monitor and manage urban green spaces, promoting sustainable urban development.\n4. Disaster Response: Sentinel-2 data aids in disaster management, providing timely information for emergency response and recovery efforts.\n5. Flood Monitoring: Sentinel-1 Synthetic Aperture Radar (SAR) data is effective in detecting and monitoring floods, assisting in risk management and mitigation.\n6. Forest Monitoring and Illegal Logging: Landsat data helps monitor forest cover and detect illegal logging activities, supporting forest conservation efforts.\n7. Forest Fires: Landsat data can be employed to detect and monitor forest fires, informing firefighting and prevention strategies.\nPolicy challenges in implementing remote sensing data for urban solutions involve: Combining remote sensing data with GIS datasets to create comprehensive solutions. Reflecting critically on how to address urban issues using remote sensing, considering factors such as funding limitations, planning stages, responsible entities, required skills, and potential benefits. Aligning remote sensing-based solutions with global policy documents, such as the New Urban Agenda and the Sustainable Development Goals (SDGs), to ensure coherence with global agendas. Identifying and engaging relevant stakeholders in the planning and implementation process to ensure the success and sustainability of remote sensing-based solutions."
  },
  {
    "objectID": "Diary8.html#summary",
    "href": "Diary8.html#summary",
    "title": "8  Diary: Temperature and policy",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nHeat islands in remote sensing refer to the phenomenon where urban areas exhibit significantly higher temperatures compared to their surrounding rural regions. This is primarily due to the alteration of land surfaces and the concentration of human activities in these areas. Remote sensing plays a crucial role in studying and monitoring urban heat islands by providing reliable, high-resolution, and time-series data. Using satellite imagery and thermal infrared sensors, remote sensing techniques enable the identification, mapping, and quantification of heat islands. Key factors that contribute to urban heat island formation include land cover change, building materials, vegetation loss, and anthropogenic heat emissions. By analyzing data collected through remote sensing, researchers can effectively monitor urban heat islands, identify patterns and trends, and propose strategies for urban planning and management. These strategies include increasing green spaces, implementing cool roofing and pavement materials, and promoting energy-efficient designs in urban infrastructure. Overall, remote sensing offers valuable insights into the complex interplay of factors that contribute to the formation of urban heat islands, ultimately helping to mitigate their environmental impact."
  },
  {
    "objectID": "Diary8.html#reflection",
    "href": "Diary8.html#reflection",
    "title": "8  Diary: Temperature and policy",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nRemote sensing in urban heat island (UHI) studies has proven to be a powerful and versatile tool in understanding the complex dynamics of urban environments. The ability to acquire high-resolution, time-series data on land surface temperature, land cover, and vegetation indices has enabled researchers to analyze and monitor the development of UHIs in cities across the world. What makes this approach particularly interesting is its capacity to reveal the intricate relationships between urbanization, land cover change, and temperature variations on a larger scale and over time. The application of remote sensing in UHI studies has important implications for urban planning and environmental management. By identifying the factors contributing to UHI formation and the areas most affected, policymakers can make informed decisions to promote sustainable urban development, such as increasing green spaces, implementing cool roofing and pavement materials, and encouraging energy-efficient building designs. The usefulness of remote sensing data and tools extends beyond UHI studies, as they can be applied to various other fields, including:\n\nClimate change: Remote sensing can track changes in temperature, precipitation, and vegetation patterns over time, providing valuable insights into the impacts of climate change on ecosystems and human societies.\nNatural disaster monitoring and management: Remote sensing can help monitor natural disasters such as floods, wildfires, and hurricanes, offering real-time information to support emergency response efforts and post-disaster recovery.\nAgriculture: Satellite imagery can be used to monitor crop health, soil moisture, and irrigation practices, enabling farmers to optimize their production and minimize the use of resources.\nWater resource management: Remote sensing data can be used to assess water availability, quality, and usage, contributing to the development of sustainable water management strategies.\nBiodiversity conservation: Remote sensing can help monitor changes in ecosystems, habitat fragmentation, and species distribution, informing conservation efforts and policies."
  },
  {
    "objectID": "Diary4.html#application",
    "href": "Diary4.html#application",
    "title": "4  Diary: Policy application",
    "section": "4.2 Application",
    "text": "4.2 Application\nMonitoring Urban Expansion and Land Use Change Problem: Unplanned and rapid urban expansion can lead to negative environmental and social impacts, such as loss of agricultural land, deforestation, and increased pollution. Policymakers need reliable data to manage urban growth and mitigate these adverse effects. Technique: Researchers in China used remote sensing data from Landsat images to monitor urban expansion and land use change in the Beijing-Tianjin-Hebei (BTH) region from 1990 to 2015 (Wu, Li, and Yu 2015).\nThey employed classification algorithms to analyze the changes in urban land, agricultural land, water bodies, and other land use types. This analysis provided valuable insights into the urbanization process and helped policymakers identify areas that require targeted interventions, such as preserving agricultural land and implementing sustainable urban planning practices.\nAssessing Air Quality and Health Impacts Problem: Air pollution is a critical issue in many urban areas, with severe consequences for public health and the environment. Policymakers need accurate and timely information to develop effective policies for reducing pollution and protecting public health. Technique: A study in the United States used satellite-derived remote sensing data from the Moderate Resolution Imaging Spectroradiometer (MODIS) to assess the relationship between fine particulate matter (PM2.5) concentrations and respiratory hospital admissions (Kloog et al. 2014).\nThe researchers developed a spatio-temporal model that combined remote sensing data, meteorological data, and land-use information to estimate daily PM2.5 concentrations at a high spatial resolution. The study provided evidence of the association between PM2.5 exposure and respiratory health issues, supporting the need for policies to reduce air pollution and mitigate its impacts on public health."
  },
  {
    "objectID": "Diary4.html#reflection",
    "href": "Diary4.html#reflection",
    "title": "4  Diary: Policy application",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nRemote sensing in policy making presents a fascinating and valuable approach to addressing various urban and environmental challenges. The ability to collect high-resolution data over vast areas and track changes over time provides a unique perspective that would be difficult, if not impossible, to achieve through traditional data collection methods.\nWhat makes remote sensing particularly interesting is its versatility and adaptability. With a wide range of sensors and data sources available, it can be applied to diverse policy areas, such as urban planning, disaster management, environmental protection, and public health. The continuous advancements in satellite technology and data processing capabilities promise even more accurate and timely information in the future, further enhancing its utility for policy making. One key advantage of remote sensing is its potential for integration with other datasets, such as demographic, economic, and social data. This allows for a more comprehensive understanding of complex urban systems, enabling policymakers to make informed decisions that consider the interdependencies between various factors.\nHowever, there are also limitations to remote sensing in policy making. Satellite data may be subject to errors, such as atmospheric distortions or sensor malfunctions, which can affect the accuracy of the information. Additionally, remote sensing data is often retrospective, meaning that it may not always be suitable for addressing immediate, real-time concerns. Moreover, the effective use of remote sensing data for policy making requires expertise in data processing, analysis, and interpretation. This may present a barrier for some organizations or governments with limited resources or technical capacity.\n\n\n\n\nKloog, Itai, Alexandra A. Chudnovsky, Allan C. Just, Francesco Nordio, Petros Koutrakis, Brent A. Coull, Alexei Lyapustin, Yujie Wang, and Joel Schwartz. 2014. “A New Hybrid Spatio-Temporal Model for Estimating Daily Multi-Year PM2.5 Concentrations Across Northeastern USA Using High Resolution Aerosol Optical Depth Data.” Atmospheric Environment 95 (October): 581–90. https://doi.org/10.1016/j.atmosenv.2014.07.014.\n\n\nWu, Yanyan, Shuyuan Li, and Shixiao Yu. 2015. “Monitoring Urban Expansion and Its Effects on Land Use and Land Cover Changes in Guangzhou City, China.” Environmental Monitoring and Assessment 188 (1): 54. https://doi.org/10.1007/s10661-015-5069-2."
  },
  {
    "objectID": "Diary5.html#summary",
    "href": "Diary5.html#summary",
    "title": "5  Diary: Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nThis week, we mainly covered the basic features of Google Earth Engine and how to use it. In the class. Cloud-based platform that allows users to analyze and visualize large amounts of geospatial data from various sources, including satellite imagery, climate data, and terrain information. It provides access to pre-processed data and tools for data analysis, such as machine learning algorithms, image classification, and time series analysis. We also learned about the data format used in GEE, which is raster, and what a collection is, which refers to several images or polygons. Additionally, we discussed the differences between client-side and server-side processing, as well as some common issues that can arise when using GEE, such as loops and mapping. Furthermore, the class went into detail on how to use GEE, including how to load datasets and perform typical operations in GEE, such as reducing images, regression, joins, and filtering."
  },
  {
    "objectID": "Diary5.html#reflection",
    "href": "Diary5.html#reflection",
    "title": "5  Diary: Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nWhat is particularly interesting about GEE is its cloud-based architecture, which allows users to access and process vast amounts of data without the need for high-performance computing resources. This democratizes access to satellite imagery and other geospatial data, making it available to researchers, policymakers, and organizations around the world. The data and tools provided by GEE are likely to become even more useful in the future as the availability and resolution of satellite imagery continue to improve. As new satellites are launched and data collection techniques are refined, GEE will enable us to monitor the Earth’s surface with increasing accuracy and detail. This will facilitate more effective decision-making in areas such as land management, conservation, urban planning, and disaster response. Furthermore, as machine learning and artificial intelligence technologies continue to advance, the integration of these techniques within GEE has the potential to significantly enhance the analysis of geospatial data. This can lead to more accurate and sophisticated models of environmental phenomena and improved predictions of future events. Despite its many advantages, GEE may not be the perfect solution for every geospatial problem, particularly for highly localized or specialized analyses that require data with a finer resolution or different datasets than those currently available in GEE. However, the ongoing development of similar platforms, either as extensions to GEE or as independent tools, can help address these limitations and ensure that the power of geospatial data analysis is accessible to an even broader range of users and applications.\n\n\n\n\nKim, Do-Hyung, Joseph O. Sexton, Praveen Noojipady, Chengquan Huang, Anupam Anand, Saurabh Channan, Min Feng, and John R. Townshend. 2014. “Global, Landsat-Based Forest-Cover Change from 1990 to 2000.” Remote Sensing of Environment 155 (December): 178–93. https://doi.org/10.1016/j.rse.2014.08.017.\n\n\nPekel, Jean-François, Andrew Cottam, Noel Gorelick, and Alan S. Belward. 2016. “High-Resolution Mapping of Global Surface Water and Its Long-Term Changes.” Nature 540 (7633): 418–22. https://doi.org/10.1038/nature20584."
  },
  {
    "objectID": "Diary6.html#summary",
    "href": "Diary6.html#summary",
    "title": "6  Diary: Classification I",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nThis lesson mainly covered how classified data is used and how to classify remotely sensed data. In remote sensing, data is generally classified into landcover data and value data. Landcover data is commonly used in fields such as urban expansion, urban green spaces, and monitoring forests, while estimating value is commonly used in fields such as air pollution and forest fires.\nIn terms of data processing, commonly used methods include classification tree, regression tree, random forests, and image classification.\nClassification Tree: A classification tree is a decision tree used for solving classification problems. It is a tree-like structure where each internal node represents a decision based on a specific feature, and each leaf node represents the predicted class label. Classification trees are used to classify instances into discrete classes.\nRegression Tree: A regression tree is a decision tree used for solving regression problems. Like a classification tree, it is a tree-like structure, but instead of class labels, the leaf nodes represent continuous values or numerical predictions. Regression trees are used to model the relationship between a dependent continuous variable and a set of independent variables.\nRandom Forests: A random forest is an ensemble learning method that combines multiple decision trees (either classification or regression trees) to improve prediction accuracy and reduce overfitting. It works by constructing multiple trees and aggregating their predictions, either by majority voting (for classification problems) or averaging (for regression problems). Random forests introduce randomness by bootstrapping the training data for each tree and selecting a random subset of features for each split, which results in better generalization and increased robustness compared to single decision trees.\nIn image classification, the commonly used supervised method is machine learning, while the commonly used unsupervised method is clustering (such as k-means and DBSCAN)."
  },
  {
    "objectID": "Diary6.html#application",
    "href": "Diary6.html#application",
    "title": "6  Diary: Classification I",
    "section": "6.2 Application",
    "text": "6.2 Application\nRegression Tree in Remote Sensing - Estimating Crop Yield Problem: Accurate estimation of crop yield is essential for effective agricultural management, food security, and economic planning. Remote sensing data can provide valuable information to estimate crop yield, but the relationships between the remotely sensed data and crop yield can be complex and nonlinear. Technique Details: Regression tree models, which are a type of decision tree model, can be used to address this issue. They work by recursively partitioning the input data into subsets based on the feature that best explains the variance in the target variable (in this case, crop yield). This process is repeated until a stopping criterion is met, resulting in a tree structure that can predict crop yield based on the input features. Remote sensing data such as vegetation indices (e.g., NDVI) and meteorological data can be used as input features to build the regression tree model (Gitelson et al. 2003).\nRandom Forest in Remote Sensing - Land Cover Classification Problem: Land cover classification is a fundamental task in remote sensing, which involves identifying and categorizing various land cover types (e.g., urban, forest, water, etc.) based on remotely sensed data. Accurate land cover classification is crucial for environmental monitoring, urban planning, and natural resource management. Technique Details: Random Forest is an ensemble learning method that constructs a multitude of decision trees during training and outputs the mode of the classes (classification) or mean prediction (regression) of the individual trees. It can be used for land cover classification using remote sensing data such as multispectral or hyperspectral imagery. The random forest classifier can handle large datasets and high-dimensional feature spaces, making it suitable for remote sensing applications. The model can also provide an estimation of variable importance, which can help in understanding the relationships between remote sensing data and land cover types (Pal 2005)."
  },
  {
    "objectID": "Diary6.html#reflection",
    "href": "Diary6.html#reflection",
    "title": "6  Diary: Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nThe usage of classification techniques in remote sensing has been interesting and transformative in various fields, including environmental monitoring, urban planning, and natural resource management. The ability to accurately classify land cover, vegetation types, and other features based on remotely sensed data has significantly improved our understanding of the Earth’s surface and its dynamics. As I reflect on classification usage in remote sensing, several aspects stand out as particularly interesting and relevant for the future.\n\nAdvancements in machine learning techniques: The emergence of advanced machine learning algorithms, such as support vector machines, random forests, and deep learning, has significantly improved the accuracy and efficiency of remote sensing classification tasks. These algorithms can handle large datasets, high-dimensional feature spaces, and complex relationships between input features and output classes, making them well-suited for remote sensing applications.\nHigh-resolution and multispectral data: The increasing availability of high-resolution and multispectral satellite imagery has opened up new possibilities for remote sensing classification tasks. These data sources provide more detailed information about the Earth’s surface, enabling more precise and accurate classification results. This trend is expected to continue as satellite technology advances, offering even higher spatial, spectral, and temporal resolutions.\nIntegration of various data sources: The combination of remote sensing data with other data sources, such as ground-based observations, LiDAR, or socio-economic data, has the potential to improve classification accuracy and provide more comprehensive insights. This data fusion approach can help researchers and decision-makers better understand the relationships between different aspects of the Earth’s surface and their changes over time.\nReal-time monitoring and change detection: The increasing temporal resolution of satellite data allows for real-time monitoring of the Earth’s surface and the detection of changes in land cover, vegetation, and other features. This capability is crucial for understanding and addressing pressing environmental issues, such as deforestation, urbanization, and climate change impacts.\nChallenges and future directions: Despite the many advances in remote sensing classification, several challenges remain. These include dealing with data uncertainty, addressing the imbalance in training data, and improving classification accuracy in complex and heterogeneous landscapes. In the future, further advancements in machine learning algorithms, data sources, and data fusion techniques are expected to address these challenges and continue to push the boundaries of remote sensing classification.\n\n\n\n\n\nGitelson, Anatoly A., Andrés Viña, Timothy J. Arkebauer, Donald C. Rundquist, Galina Keydan, and Bryan Leavitt. 2003. “Remote Estimation of Leaf Area Index and Green Leaf Biomass in Maize Canopies.” Geophysical Research Letters 30 (5). https://doi.org/10.1029/2002GL016450.\n\n\nPal, M. 2005. “Random Forest Classifier for Remote Sensing Classification.” International Journal of Remote Sensing 26 (1): 217–22. https://doi.org/10.1080/01431160412331269698."
  },
  {
    "objectID": "Diary7.html#summary",
    "href": "Diary7.html#summary",
    "title": "7  Diary: Classification II",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nTwo notable techniques used for land cover classification are Simple Linear Iterative Clustering (SLIC) and sub-pixel analysis, which includes methods like the Spectral Mixture Analysis (SMA) and Vegetation-Impervious Surface-Soil (V-I-S) model. Simple Linear Iterative Clustering (SLIC) is an unsupervised classification technique used for segmenting an image into homogenous regions based on spectral and spatial information. SLIC works by iteratively refining cluster centroids and partitioning the image into segments. The technique is computationally efficient and produces high-quality segmentation results, making it suitable for land cover classification applications. Sub-pixel analysis focuses on quantifying the proportion of different land cover types within a pixel, rather than assigning a single class to each pixel. This approach is particularly useful for high-resolution remote sensing data, where mixed pixels are common. Spectral Mixture Analysis (SMA) is a sub-pixel analysis method that involves decomposing the mixed pixel’s spectral signature into a linear combination of spectral endmembers, representing the pure signatures of the different land cover types. SMA estimates the fractional cover of each land cover type within the pixel, providing a more detailed representation of the land cover composition. The Vegetation-Impervious Surface-Soil (V-I-S) model is another sub-pixel analysis technique used for estimating the proportion of vegetation, impervious surfaces (e.g., buildings, roads), and soil within a pixel. The V-I-S model utilizes multiple spectral indices and assumes that the pixel’s reflectance is a linear mixture of the three components. By estimating the fractional cover of each component, the V-I-S model provides valuable information for urban planning, environmental monitoring, and natural resource management.\nError matrix (also known as confusion matrix) and Kappa coefficient are widely used evaluation metrics for assessing the performance of classification models in remote sensing and other fields. The error matrix is a square matrix that represents the distribution of observed (ground truth) and predicted (classification) values for different classes. It provides a detailed view of classification performance, including correct and incorrect predictions for each class. The main diagonal of the error matrix represents correct classifications, while the off-diagonal elements represent misclassifications. From the error matrix, several accuracy measures can be derived, including overall accuracy, user’s accuracy (producer’s accuracy), and commission and omission errors. Overall accuracy is the ratio of correctly classified samples to the total number of samples, while user’s and producer’s accuracy indicate the reliability of a specific class in the classification. The Kappa coefficient is an additional accuracy measure that accounts for the agreement expected by chance. It ranges from -1 to 1, with values closer to 1 indicating higher agreement between observed and predicted classifications. A Kappa value of 0 suggests that the classification is no better than random chance, and negative values indicate a disagreement between the classifications. The Kappa coefficient is particularly useful when dealing with imbalanced datasets, as it provides a more robust assessment of classification performance compared to overall accuracy.\nHowever, there are some issues associated with the error matrix and Kappa coefficient:\n\nSampling bias: The accuracy measures derived from the error matrix and Kappa coefficient can be sensitive to the sampling strategy used for collecting reference data. An unrepresentative or biased sample may lead to misleading results.\nClass imbalance: In cases of imbalanced datasets, the overall accuracy and Kappa coefficient may not provide a complete picture of classification performance, as they may be dominated by the performance of the majority class.\nKappa paradox: In some situations, a low Kappa value may be observed despite high overall accuracy. This issue, known as the Kappa paradox, occurs when there is a high degree of imbalance between classes or when the classification errors are systematically distributed.\n\nImage cross-validation is a robust model evaluation technique used in remote sensing and other fields to assess the performance of classification and regression models. Cross-validation aims to provide an unbiased estimate of a model’s performance by testing it on multiple data subsets, ensuring that the model generalizes well to unseen data. In image cross-validation, the input image data is divided into multiple non-overlapping subsets, commonly referred to as folds. The model is trained on a combination of these folds (training set) and then tested on the remaining fold (validation set). This process is repeated multiple times, with each fold serving as the validation set once. The model’s performance is then averaged across all iterations to obtain an overall performance estimate."
  },
  {
    "objectID": "Diary7.html#application",
    "href": "Diary7.html#application",
    "title": "7  Diary: Classification II",
    "section": "7.2 Application",
    "text": "7.2 Application\nThe techniques discussed above, including land cover classification methods (SLIC, SMA, and V-I-S model), evaluation metrics (error matrix and Kappa coefficient), and validation strategies (image cross-validation), have been extensively applied in remote sensing literature, policy-making, and various studies. These techniques play a significant role in advancing our understanding of the Earth’s surface, environmental monitoring, and decision-making processes. Land cover classification methods, such as Simple Linear Iterative Clustering (SLIC), Spectral Mixture Analysis (SMA), and the Vegetation-Impervious Surface-Soil (V-I-S) model, have been widely used in diverse applications. For instance, SLIC has been employed in large-scale land cover mapping, urban growth monitoring, and change detection studies. SMA and the V-I-S model have found applications in sub-pixel land cover analysis, urban planning, and natural resource management. These methods have been successfully combined with machine learning algorithms and data fusion techniques to improve classification accuracy and provide comprehensive insights into the Earth’s surface. Evaluation metrics like the error matrix and Kappa coefficient have been extensively used in remote sensing literature to assess classification performance. Researchers often utilize these metrics to compare the performance of different classification algorithms or to evaluate the impact of different data sources and preprocessing techniques on classification results. Policymakers and decision-makers also rely on these evaluation metrics to assess the quality and reliability of land cover maps and other remote sensing products. Image cross-validation techniques, such as K-fold, stratified K-fold, Leave-One-Out, and spatial cross-validation, have been widely adopted in remote sensing studies to ensure the reliability and generalizability of classification and regression models. Researchers often employ these validation strategies to select the best model for a specific application or to optimize model parameters. Spatial cross-validation, in particular, has gained attention in recent years due to the recognition of the importance of spatial autocorrelation in remote sensing data."
  },
  {
    "objectID": "Diary7.html#refelction",
    "href": "Diary7.html#refelction",
    "title": "7  Diary: Classification II",
    "section": "7.3 Refelction",
    "text": "7.3 Refelction\nWhat makes classification in remote sensing interesting is the continuous development of new algorithms and techniques, as well as the integration of machine learning and artificial intelligence. These advancements have led to improved classification accuracy and the ability to handle increasingly complex and high-resolution datasets. Additionally, the fusion of data from multiple sensors and platforms has enabled the generation of more comprehensive and detailed land cover maps, providing insights into land surface processes at various temporal and spatial scales. The importance of accuracy assessment and validation techniques, such as the error matrix, Kappa coefficient, and image cross-validation, is crucial for ensuring the reliability and generalizability of classification models. These techniques provide a robust understanding of a model’s performance, accounting for factors such as class imbalance, sampling bias, and spatial autocorrelation. In the future, these tools and methods will continue to be useful as remote sensing data becomes more abundant, with an increasing number of satellite missions and higher-resolution sensors. The ability to efficiently process and analyze vast amounts of data will be critical in addressing global challenges, such as climate change, deforestation, urbanization, and food security. However, there might be some limitations to the existing classification techniques, especially when dealing with complex, heterogeneous landscapes or when trying to capture rapid land cover changes. In these cases, novel approaches, such as deep learning or data fusion techniques, might be more suitable for capturing the intricate patterns and dynamics in the data."
  },
  {
    "objectID": "Diary5.html#application",
    "href": "Diary5.html#application",
    "title": "5  Diary: Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\nDeforestation Monitoring and Analysis Problem: Deforestation is a major environmental issue that contributes to climate change, loss of biodiversity, and disruption of local communities’ livelihoods. Monitoring deforestation and understanding its patterns can help inform policy and conservation efforts. Google Earth Engine (GEE) Application: GEE can be used to monitor and analyze deforestation in near real-time using satellite imagery. By leveraging GEE’s vast library of datasets (e.g., Landsat and Sentinel), users can develop algorithms to detect changes in forest cover over time. One such example is the Global Forest Change project (Hansen et al., 2013), which provides annual tree cover loss data from 2000 to 2020. Using GEE, users can: 1. Import relevant datasets (e.g., Landsat, Sentinel, and Global Forest Change). 2. Apply pre-processing steps, such as cloud masking, to improve the quality of the input images. 3. Perform classification of land cover types (forest, non-forest) using supervised or unsupervised machine learning techniques. 4. Calculate the difference between the images from different time periods to detect forest cover changes. 5. Visualize the results and export them as maps or data files (Kim et al. 2014).\nLimitations: The accuracy of deforestation detection depends on the quality of the input data and the classification algorithm used. Cloud cover can also limit the availability of satellite images in some regions. Additionally, the temporal resolution of the available satellite data may not be sufficient for detecting rapid deforestation events.\nFlood Risk Assessment and Management Problem: Climate change has increased the frequency and severity of flood events worldwide. Accurate flood risk assessment and management are crucial for minimizing the loss of life and property. Google Earth Engine (GEE) Application: GEE can be used to model and analyze flood risk by combining various datasets, such as digital elevation models (DEMs), land use/land cover, precipitation, and river flow data. An example of this application is the Global Flood Risk Monitoring project, which uses GEE to estimate flood risks at a global scale. Using GEE, users can: 6. Import relevant datasets (e.g., SRTM, GPM, and land use/land cover data). 7. Develop hydrological models to simulate river flow and flood inundation using inputs such as precipitation and elevation data. 8. Combine the simulated flood data with land use/land cover data to assess the impact of floods on various land types and infrastructure. 9. Analyze historical flood events to estimate the probability of future floods and identify high-risk areas. 10. Visualize the results as maps or graphs and export the data for further analysis. Limitations: The accuracy of flood risk assessment depends on the quality and resolution of the input datasets and the hydrological models used. Data gaps or inaccuracies in the input data can lead to errors in flood risk estimates. Additionally, GEE might not be suitable for simulating highly detailed or localized flood events due to its global focus and resolution constraints (Pekel et al. 2016)."
  },
  {
    "objectID": "Diary8.html#application",
    "href": "Diary8.html#application",
    "title": "8  Diary: Temperature and policy",
    "section": "8.2 Application",
    "text": "8.2 Application\nAccording to a study, researcher employed remote sensing techniques to examine the temporal and spatial patterns of surface urban heat islands in Shenzhen between 1990 and 2005. They used thermal infrared bands to retrieve land surface temperature (LST) and employed several vegetation indices, including the Normalized Difference Vegetation Index (NDVI), to characterize the relationship between urbanization and the UHI effect. The study found a significant increase in the UHI intensity during the 15-year period, mainly due to rapid urban expansion and the reduction of green spaces. Additionally, the research identified a strong negative correlation between LST and NDVI, highlighting the crucial role of vegetation in mitigating UHIs. By incorporating such research into urban planning policies, city officials can make informed decisions to counteract UHI effects, such as increasing green spaces, implementing green roofs, and promoting the use of cool materials for urban construction. This example demonstrates how remote sensing data and methods have been applied in literature to study the UHI phenomenon, providing valuable insights for researchers, policymakers, and urban planners to develop effective strategies for mitigating the adverse impacts of urban heat islands."
  }
]